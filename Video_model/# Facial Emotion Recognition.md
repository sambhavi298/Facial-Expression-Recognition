# Facial Emotion Recognition (Internship Project)

This project performs facial emotion recognition using deep learning. It supports training from scratch using FER2013, RAF-DB, and CK+ datasets, and allows inference from both images and video files.

## ğŸ“ Project Structure

```
facial_emotion_recognition/
â”œâ”€â”€ data/                  # Place your datasets here
â”œâ”€â”€ outputs/               # Trained models, logs, plots
â”œâ”€â”€ src/                   # Training and preprocessing scripts
â”œâ”€â”€ infer.py              # Run emotion prediction on images/videos
â”œâ”€â”€ train_V.py            # Train the model from scratch
â”œâ”€â”€ evaluate.py           # Evaluate the model on test set
â””â”€â”€ requirements.txt       # Install dependencies
```

## ğŸ§ª How to Run

### 1. Preprocess Datasets
Ensure your FER2013, RAF-DB, and CK+ datasets are available and modify paths in `data_loader.py` if needed.

### 2. Train the Model
```bash
python train_V.py
```

Trained model will be saved to:
```
outputs/video_emotion_model.h5
```

### 3. Evaluate the Model
```bash
python evaluate.py
```

This generates a confusion matrix in:
```
outputs/confusion_matrix.png
```

### 4. Inference from Image
```bash
python infer.py --image path/to/image.jpg
```

### 5. Inference from Video
```bash
python infer.py --video path/to/video.mp4
```

Press `Q` to exit video window.

## ğŸ“Š TensorBoard (Optional)
To view training logs:
```bash
tensorboard --logdir=outputs/logs
```

## âœ… Emotion Labels Used
['neutral', 'calm', 'happy', 'sad', 'angry', 'fear', 'disgust', 'surprise']

---
